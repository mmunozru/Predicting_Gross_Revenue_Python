{"cells":[{"cell_type":"markdown","source":["Author: Marissa Munoz-Ruiz <br>\nSLU Capstone: HDS 5960 <br>\nDatabricks Notebook: SLU_Capstone_ML\n\n---\n##### Goal of Script: Process and Compare Regression ML Models \n\n* Multiple Linear Regression, Extreme Gradient Boosting, and Neural Networks were used\n  * Note: NN models can't handle null values  \n* RMSE was used as the performance metric"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d7097871-9c19-413f-b321-9885f492303e","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%pip install xgboost tensorflow"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"09ba37cb-d6be-4158-bf29-85b645e4f6cd","inputWidgets":{},"title":"Install Modules for ML"}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Python interpreter will be restarted.\nCollecting xgboost\n  Downloading xgboost-1.7.2-py3-none-manylinux2014_x86_64.whl (193.6 MB)\nCollecting tensorflow\n  Downloading tensorflow-2.11.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.9/site-packages (from xgboost) (1.21.5)\nRequirement already satisfied: scipy in /databricks/python3/lib/python3.9/site-packages (from xgboost) (1.7.3)\nCollecting flatbuffers>=2.0\n  Downloading flatbuffers-22.12.6-py2.py3-none-any.whl (26 kB)\nCollecting tensorflow-estimator<2.12,>=2.11.0\n  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\nCollecting termcolor>=1.1.0\n  Downloading termcolor-2.1.1-py3-none-any.whl (6.2 kB)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow) (58.0.4)\nRequirement already satisfied: packaging in /databricks/python3/lib/python3.9/site-packages (from tensorflow) (21.3)\nCollecting tensorboard<2.12,>=2.11\n  Downloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\nCollecting astunparse>=1.6.0\n  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\nCollecting grpcio<2.0,>=1.24.3\n  Downloading grpcio-1.51.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\nCollecting keras<2.12,>=2.11.0\n  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\nCollecting google-pasta>=0.1.1\n  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\nCollecting opt-einsum>=2.3.2\n  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\nRequirement already satisfied: six>=1.12.0 in /databricks/python3/lib/python3.9/site-packages (from tensorflow) (1.16.0)\nCollecting tensorflow-io-gcs-filesystem>=0.23.1\n  Downloading tensorflow_io_gcs_filesystem-0.28.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\nCollecting libclang>=13.0.0\n  Downloading libclang-14.0.6-py2.py3-none-manylinux2010_x86_64.whl (14.1 MB)\nCollecting absl-py>=1.0.0\n  Downloading absl_py-1.3.0-py3-none-any.whl (124 kB)\nCollecting wrapt>=1.11.0\n  Downloading wrapt-1.14.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\nRequirement already satisfied: protobuf<3.20,>=3.9.2 in /databricks/python3/lib/python3.9/site-packages (from tensorflow) (3.19.4)\nRequirement already satisfied: typing-extensions>=3.6.6 in /databricks/python3/lib/python3.9/site-packages (from tensorflow) (4.1.1)\nCollecting gast<=0.4.0,>=0.2.1\n  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\nCollecting h5py>=2.9.0\n  Downloading h5py-3.7.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.5 MB)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /databricks/python3/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\nCollecting markdown>=2.6.8\n  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\nCollecting tensorboard-data-server<0.7.0,>=0.6.0\n  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\nCollecting google-auth-oauthlib<0.5,>=0.4.1\n  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\nCollecting tensorboard-plugin-wit>=1.6.0\n  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\nCollecting werkzeug>=1.0.1\n  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)\nRequirement already satisfied: requests<3,>=2.21.0 in /databricks/python3/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.27.1)\nCollecting google-auth<3,>=1.6.3\n  Downloading google_auth-2.15.0-py2.py3-none-any.whl (177 kB)\nCollecting cachetools<6.0,>=2.0.0\n  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\nCollecting rsa<5,>=3.1.4\n  Downloading rsa-4.9-py3-none-any.whl (34 kB)\nCollecting pyasn1-modules>=0.2.1\n  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\nCollecting requests-oauthlib>=0.7.0\n  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\nCollecting importlib-metadata>=4.4\n  Downloading importlib_metadata-5.1.0-py3-none-any.whl (21 kB)\nCollecting zipp>=0.5\n  Downloading zipp-3.11.0-py3-none-any.whl (6.6 kB)\nCollecting pyasn1<0.5.0,>=0.4.6\n  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (3.3)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /databricks/python3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.0.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.26.9)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2021.10.8)\nCollecting oauthlib>=3.0.0\n  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\nCollecting MarkupSafe>=2.1.1\n  Downloading MarkupSafe-2.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /databricks/python3/lib/python3.9/site-packages (from packaging->tensorflow) (3.0.4)\nInstalling collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, MarkupSafe, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, keras, h5py, google-pasta, gast, flatbuffers, astunparse, xgboost, tensorflow\n  Attempting uninstall: MarkupSafe\n    Found existing installation: MarkupSafe 2.0.1\n    Not uninstalling markupsafe at /databricks/python3/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-3150aaf5-f757-415b-8660-60a026dde825\n    Can't uninstall 'MarkupSafe'. No files were found to uninstall.\nSuccessfully installed MarkupSafe-2.1.1 absl-py-1.3.0 astunparse-1.6.3 cachetools-5.2.0 flatbuffers-22.12.6 gast-0.4.0 google-auth-2.15.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.51.1 h5py-3.7.0 importlib-metadata-5.1.0 keras-2.11.0 libclang-14.0.6 markdown-3.4.1 oauthlib-3.2.2 opt-einsum-3.3.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.11.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-io-gcs-filesystem-0.28.0 termcolor-2.1.1 werkzeug-2.2.2 wrapt-1.14.1 xgboost-1.7.2 zipp-3.11.0\nPython interpreter will be restarted.\n"]}],"execution_count":0},{"cell_type":"code","source":["%run ./SLU_Capstone_Preprocessing "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"bea74d56-368d-4bd7-a5fb-921f9acc7eb3","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/plain":[],"application/vnd.databricks.v1+bamboolib_hint":"{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}"}},{"output_type":"stream","output_type":"stream","name":"stdout","text":["Out[11]: 'gross_revenue ~ total_bad_debt_expense + medicaid_charges + cost_to_charge_ratio + buildings + major_movable_equipment + salaries_wages_and_fees_payable + total_unreimbursed_and_uncompensated_care + net_income + cash_on_hand_and_in_banks + total_assets + cost_of_uncompensated_care + depreciation_cost + inventory + other_assets + total_fund_balances + total_salaries_from_worksheet_a + less_total_operating_expense + total_days_v_xviii_xix_unknown_total_for_all_subproviders + accounts_payable + total_bed_days_available + less_contractual_allowance_and_discounts_on_patients_accounts + net_revenue_from_medicaid + net_income_from_service_to_patients + outpatient_total_charges + overhead_nonsalary_costs + prepaid_expenses + total_discharges_v_xviii_xix_unknown_total_for_all_subproviders + fte_employees_on_payroll + accounts_receivable + general_fund_balance + total_liabilities'"]},{"output_type":"stream","output_type":"stream","name":"stdout","text":["/databricks/python/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: divide by zero encountered in true_divide\n  correlation_coefficient /= X_norms\n/databricks/python/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:358: RuntimeWarning: invalid value encountered in true_divide\n  f_statistic = corr_coef_squared / (1 - corr_coef_squared) * deg_of_freedom\n"]},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gross_revenue</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>5.350800e+04</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>5.409652e+08</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.082218e+09</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-1.770319e+08</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>3.811593e+07</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.271728e+08</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>5.918225e+08</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>2.939014e+10</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>gross_revenue</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>5.350800e+04</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>5.409652e+08</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>1.082218e+09</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>-1.770319e+08</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>3.811593e+07</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>1.271728e+08</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>5.918225e+08</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>2.939014e+10</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Import Libraries"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"88030170-f8d9-4b6a-bf76-645a8f724173","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["## Import Modules\nimport os\nimport sys\nimport time\nimport random \n#import numpy as np\n#import pandas as pd\nimport seaborn as sns\nfrom patsy import dmatrices\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import mean_squared_error as MSE\n\nfrom xgboost import XGBRegressor\nfrom xgboost import cv\nfrom xgboost import DMatrix\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.regularizers import l1"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"236ecf5f-8993-4153-bc1e-e4a13a433af6","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### Develop Functions for Machine Learning Models"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8c0592f3-bd44-4a18-97b7-0e34d8b8b88d","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["def LinearRegression_predict(data_df,y_var):\n    \n    t0 = time.time()\n    \n    ## Create formula for all variables in model\n    vars_remove = [y_var]\n    vars_left = set(data_df.columns) - set(vars_remove)\n    formula = y_var + \" ~ \" + \" + \".join(vars_left)\n\n    ## Use Patsy to create model matrices\n    Y,X = dmatrices(formula,data_df,return_type='dataframe')\n\n    ## Split Data into training and sample\n    X_train, X_test, Y_train, Y_test = train_test_split(X,\n                                                        np.ravel(Y), # prevents dimensionality error later!\n                                                        test_size=0.20,\n                                                        random_state=30)\n\n    ## Fit Linear Regression model\n    model = LinearRegression(fit_intercept=True) \n    model.fit(X_train,Y_train)\n\n    ## Get 5-CV train results\n    cv = KFold(n_splits=5,shuffle=True,random_state=None)\n    train_results = cross_val_score(model,X_train,Y_train,scoring='neg_mean_squared_error',cv=cv,n_jobs=-1)\n    train_rmse = np.sqrt(np.absolute(train_results).mean())\n\n    ## Predict Linear model\n    pred = model.predict(X_test)\n    test_rmse = np.sqrt(MSE(Y_test, pred))\n\n    t1 = time.time()\n\n    model_str = \"ScikitLearn_LinearRegression\"\n\n    return [model_str,train_rmse,test_rmse,(t1-t0)]"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f35534dd-89e4-433e-b09e-ff02a66d4547","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["def xgb_predict(data_df,y_var):\n    \n    t0 = time.time()\n    X,Y = data_df.loc[:,data_df.columns != y_var], data_df.loc[:,data_df.columns == y_var]\n    X_train, X_test, Y_train, Y_test = train_test_split(X,\n                                                        Y, # prevents dimensionality error later!\n                                                        test_size=0.20,\n                                                        random_state=30)\n\n    ## Use Dmatrix object optimized for XGBoost\n    train_dmatrix = DMatrix(data = X_train, label = Y_train)\n    test_dmatrix = DMatrix(data = X_test, label = Y_test)\n\n    ## Create CV df w/ hyperparameters \n    params = {\"objective\":\"reg:linear\",\n              'colsample_bytree': 1, \n              'learning_rate': 0.1,\n              'gamma': 0,\n              'max_depth': 1, \n              'min_child_weight':1,\n              'subsample':1,\n              'nthread':3}\n    \n#     params = {\"objective\":\"reg:linear\",\n#                   'colsample_bytree': 1, \n#                   'learning_rate': 0.1,\n#                   'gamma': 0,\n#                   'max_depth': 5, \n#                   'min_child_weight':1,\n#                   'subsample':1,\n#                   'nthread':3}\n        \n    ## Fit XGB model\n    model = XGBRegressor(**params, verbosity=0)\n    model.fit(X_train,Y_train)\n\n    cv = KFold(n_splits=5,shuffle=True,random_state=None)\n\n    ## Get 5-CV train results\n    train_results = cross_val_score(model,X_train,Y_train,scoring='neg_mean_squared_error',cv=cv,n_jobs=-1)\n    train_rmse = np.sqrt(np.absolute(train_results).mean())\n\n    ## Predict XGB model\n    pred = model.predict(X_test)\n    test_rmse = np.sqrt(MSE(Y_test, pred))\n\n    t1 = time.time()\n    \n    model_str = \"ScikitLearn_XGboost\"\n\n    return [model_str,train_rmse,test_rmse,(t1-t0)]"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e3d36bd4-302b-4417-9ee5-5af20696241a","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["def NN_model(data_df,y_var):\n    \n    t0 = time.time()\n    \n    # create training & testing data sets\n    X,Y = data_df.loc[:,data_df.columns != y_var], data_df.loc[:,data_df.columns == y_var]\n    X_train, X_test, Y_train, Y_test = train_test_split(X,Y,train_size=0.8,random_state=30)\n\n    ## Create NN model structure\n    model = Sequential()\n    model.add(Dense(64,\n                    activation='relu',\n                    input_dim=X_train.shape[1]))\n    model.add(Dense(64,\n                    activation='relu'))\n    model.add(Dense(1,\n                    activation='linear'))\n    model.compile(optimizer='rmsprop',\n                  loss='mse',\n                  metrics=['mse'])\n\n    # fit NN model/architecture to data\n    model.fit(X_train,\n              Y_train,\n              epochs=500,\n              validation_split=0.2,\n              verbose=0)\n\n    # performance metrics \n    epoch_mse = np.sqrt(np.min(model.history.history['val_mse']))\n    epoch_pos = np.argmin(model.history.history['val_mse'])\n    train_rmse = np.sqrt(model.history.history['mse'][epoch_pos])\n    \n    test_mse = model.evaluate(x=X_test,y=Y_test,verbose=0)\n    test_rmse = np.sqrt(test_mse[0])\n    \n    t1 = time.time()\n    \n    model_str = \"Tensorflow_NN\"\n    \n    return [model_str,train_rmse,test_rmse,(t1-t0)]"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4467f388-d579-4428-bf9c-bd73117c00da","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### ML Model Comparison"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c25665fb-a6d2-4d28-8a75-ff86581614de","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["#data_test = MLdata_pdf[0:100]\ndata_test = MLdata_pdf\ny_var = 'gross_revenue'\n\nresults = []\nresults.append(LinearRegression_predict(data_test,y_var))\nresults.append(xgb_predict(data_test,y_var))\nresults.append(NN_model(data_test,y_var))\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"fa01f0b0-2025-428b-b9b6-7514cb809be3","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["result_df = pd.DataFrame(results, columns = ['ML Method','Training_RMSE','Testing_RMSE','Time_Taken(s)'])\nresult_df.sort_values(by=['Testing_RMSE','Training_RMSE'],ascending=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"01fe1804-35b0-4813-a3cf-49025a7f4969","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ML Method</th>\n      <th>Training_RMSE</th>\n      <th>Testing_RMSE</th>\n      <th>Time_Taken(s)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ScikitLearn_LinearRegression</td>\n      <td>6.901791e+07</td>\n      <td>5.398614e+07</td>\n      <td>2.139336</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ScikitLearn_XGboost</td>\n      <td>1.082431e+08</td>\n      <td>8.450359e+07</td>\n      <td>5.924739</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Tensorflow_NN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>983.395139</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ML Method</th>\n","      <th>Training_RMSE</th>\n","      <th>Testing_RMSE</th>\n","      <th>Time_Taken(s)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ScikitLearn_LinearRegression</td>\n","      <td>6.901791e+07</td>\n","      <td>5.398614e+07</td>\n","      <td>2.139336</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ScikitLearn_XGboost</td>\n","      <td>1.082431e+08</td>\n","      <td>8.450359e+07</td>\n","      <td>5.924739</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Tensorflow_NN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>983.395139</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"SLU_Capstone_ML","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4,"mostRecentlyExecutedCommandWithImplicitDF":{"commandId":2517291276824250,"dataframes":["_sqldf"]}},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
